
<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Archives: 2015 | Pumpkin</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Be grateful for each new day">
<meta property="og:type" content="website">
<meta property="og:title" content="Pumpkin">
<meta property="og:url" content="http://bearpaw.github.io/blog/blog/archives/2015/">
<meta property="og:site_name" content="Pumpkin">
<meta property="og:description" content="Be grateful for each new day">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Pumpkin">
<meta name="twitter:description" content="Be grateful for each new day">
<link rel="publisher" href="https://plus.google.com/u/0/+WeiYangplatero">

  
    <link rel="alternative" href="/blog/atom.xml" title="Pumpkin" type="application/atom+xml">
  
  
    <link rel="icon" href="/blog/favicon.ico">
  
  <link rel="stylesheet" href="/blog/css/style.css" type="text/css">

  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  
<script type="text/javascript">
  (function(w,d,t,u,n,s,e){w['SwiftypeObject']=n;w[n]=w[n]||function(){
  (w[n].q=w[n].q||[]).push(arguments);};s=d.createElement(t);
  e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e);
  })(window,document,'script','//s.swiftypecdn.com/install/v1/st.js','_st');

  _st('install','C3e3fw-XzPj6xPmhGvHa');
</script>
</head>
<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/blog/" id="logo">Pumpkin</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/blog/" id="subtitle">不积跬步，无以至千里 / 不积小流，无以成江海</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/blog/">Blog</a>
        
          <a class="main-nav-link" href="/blog/PRML">PRML</a>
        
          <a class="main-nav-link" href="/blog/Deep-Learning">Deep Learning</a>
        
          <a class="main-nav-link" href="/blog/archives">Archives</a>
        
          <a class="main-nav-link" href="http://bearpaw.github.io">About</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/blog/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      
        <div id="search-form-wrap">
          <form class="search-form" action="/blog/search/index.html" method="get" accept-charset="utf-8">
              <input type="text" id="st-search-input" class="search-form-input" placeholder="Search" />
              <input type="submit" value="" class="search-form-submit"> 
           </form>
        </div>
      
    </div>
  </div>
</header>
    <div class="outer">
      <section id="main">
  
    <article id="post-Parsing-Occluded-People-by-Flexible-Compositions" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/blog/2015/04/16/Parsing-Occluded-People-by-Flexible-Compositions/" class="article-date">
  <time datetime="2015-04-16T08:16:41.000Z" itemprop="datePublished">4月 16 2015</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      	  
		<!-- 文章目录开始 -->
		
		<!-- 文章目录结束 -->
        <p>title: Parsing Occluded People by Flexible Compositions<br>date: 2015-04-16 16:16:41<br>categories:[论文笔记]</p>
<h2 id="tags:_[pose_estimation]">tags: [pose estimation]</h2>
<blockquote>
<p>Parsing Occluded People by Flexible Compositions. Xianjie Chen, Alan Yuille. CVPR, 2015. </p>
</blockquote>
<p>这篇文章是在他们<a href="2015/03/19/Articulated-Pose-Estimation-by-a-Graphical-Model-with-Image-Dependent-Pairwise-Relations/">NIPS 14</a>的工作基础上, 加上了 occlusion handling 以处理 human part occlusion的问题.</p>
<h2 id="Motivation">Motivation</h2>
<p><img src="http://7u2pi6.com1.z0.glb.clouddn.com/blog/parsing-occluded-people-1.png" alt="Motivation"></p>
<p>通常我们做pose都是在occlusion没有那么严重的数据集上, 比如LSP, FLIC等. 但生活中往往会遇到occlusion很严重的情况 (Figure 2 (a)). 作者认为, 被遮挡的part的相邻的part能够提供一些关于occlusion的信息, 如Figure 2(b). </p>
<h2 id="Model">Model</h2>
<p>Pose的图模型还是Tree structure. 只不过作者认为, 去除被遮挡的部分, 人的part还是能连成一个subtree的. 当然本文不考虑一个人被分割为两个subtrees的情况. 因此本文提出了一个mixture model, 里面的每个component都是一个subtree, 作者称之为 flexible compositions, 如Figure 1所示.</p>
<p><img src="http://7u2pi6.com1.z0.glb.clouddn.com/blog/parsing-occluded-people-2.png" alt="flexible compositions"></p>
<p>本文的大体框架与 NIPS 14的工作非常相似, 但是增加了一个binary occlusion decoupling variable <span>$\gamma_{ij} \in \{0, 1\}$</span>, 为1 时表示 part j 需要从part i中 decouple出来. 整个模型也是包含了 unary term和IDPR term, 另外还增加了一项 Image dependent occlusion decoupling term. 这个term 表征了 j 是否应该从 i中decouple出来, 因此总的分数为:<br><img src="http://7u2pi6.com1.z0.glb.clouddn.com/parsing-occluded-people-3.png" alt="Motivation"></p>
<p>其中 A 是Unary term, R 是 IDPR term, D 是 Image dependent occlusion decoupling term, B是decoupling bias. </p>
<p>本文inference 还似乎采用了传统的 DP (message passing)和 backtrack算法. 值得注意的是CNN training的过程.</p>
<p>之前在train的时候, background patch从INRIA里面来, 作为第0类, 其他的每个patch都属于一个mixture. 现在因为要考虑occlusion信息, 每个pos patch 如果不可见, 属于第0个mixture, 否则属于第 1-K个mixture.</p>

      
    </div>
    <footer class="article-footer">
      
        <a data-url="http://bearpaw.github.io/blog/2015/04/16/Parsing-Occluded-People-by-Flexible-Compositions/" data-id="b9kky58lmpk855dp" class="article-share-link" data-share="baidu">分享到</a>
      

      
        <a href="http://bearpaw.github.io/blog/2015/04/16/Parsing-Occluded-People-by-Flexible-Compositions/#ds-thread" class="article-comment-link">Comments</a>
      

      
    </footer>
  </div>
  
</article>


  
    <article id="post-Joint-Deep-Learning-for-Pedestrian-Detection" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/blog/2015/04/05/Joint-Deep-Learning-for-Pedestrian-Detection/" class="article-date">
  <time datetime="2015-04-05T08:12:38.000Z" itemprop="datePublished">4月 5 2015</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/blog/categories/论文笔记/">论文笔记</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/blog/2015/04/05/Joint-Deep-Learning-for-Pedestrian-Detection/">Joint Deep Learning for Pedestrian Detection</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      	  
		<!-- 文章目录开始 -->
		
		<!-- 文章目录结束 -->
        <blockquote>
<p>Ouyang, Wanli, and Xiaogang Wang. “Joint deep learning for pedestrian detection.” ICCV 2013</p>
</blockquote>
<p>传统的Pedestrian detection pipeline将feature extraction, part deformation handling, occlusion handling, classification 分开做的. 本文则是提出了一个end-to-end 的DL框架, 将所有component融和在一起.</p>
<p><img src="http://www.ee.cuhk.edu.hk/~wlouyang/projects/ouyangWiccv13Joint/images/overview.jpg" alt="Joint Deep Learning Architecture"></p>
<h2 id="Model">Model</h2>
<p>Model如上图所示, 其中输入是把图像, YUV特征, edge map拼在一起得到的; filtered data是conv1 后的response map; extracted feature 是进行了4X4 stride = 4 的 average pooling 后的结果. 比较关键的是part detectionmap 和 part score. 下面详细介绍这两层.</p>
<h3 id="Part_detection_map">Part detection map</h3>
<p><img src="http://hexo-pic-zhangliliang.qiniudn.com/%E5%B0%8FQ%E6%88%AA%E5%9B%BE-20141114155334.png" alt="Part detection map"></p>
<p>如上图所示, 作者任何人的part可以按照大小分为不同level, 比如level 3 可以认为是level 2中的几个part组合而成. 注意在实现时, level 1-level 3 其实是同一个 conv 层, 共有20个part因此conv层就有20个channel. 比较特别的是不同channel的卷积核大小不同 (来表征不同的part size).</p>
<h3 id="The_deformation_layer">The deformation layer</h3>
<p>关键部分登场了. 在DPM中, 作者在model part之间的位置关系时, 定义了deformation cost, 在搜寻最佳位置时, 用了distance transform算法. 本文提出了用一种新的layer, 来模拟deformation操作. model如下图所示.</p>
<p><img src="http://7u2pi6.com1.z0.glb.clouddn.com/blog/deformation-layer.png" alt="Deformation Layer"></p>
<p>我们先直观地理解一下这一层在做什么. 在经过上一层操作后, 我们已经得到了每一个part的detection score map, 用 <span>$M_p$</span> 表示. 假定我们有 $N$ 个预先定义好的 deformation map <span>$D_{n,p}$</span>, 那么我们就能定义出 (negative) deformation cost:</p>
<p><span>$$\sum_{n=1}^N c_{n,p} D_{n,p}$$</span><br>其中 <span>$c_{n,p}$</span> 是每一个deformation map的系数, 是一个标量.</p>
<p>回顾DPM, 每个part最后的分数是 HOG score - deformation cost. 因此我们要做的操作就是把 detection score map 和 negative deformation cost map 加起来, 最终的part score map用  <span>$B_p$</span> 表示:</p>
<p><span>$$B_p = M_p + \sum_{n=1}^N c_{n,p} D_{n,p}$$</span><br>不过我们感兴趣的还是 max score, 因此再在 <span>$B_p$</span> 求一个max</p>
<p><span>$$s_p = \max_{(x,y)} B_p^{(x,y)}$$</span><br>对应的位置就是</p>
<p><span>$$(x, y)_p = \arg\max_{(x,y)} B_p^{(x,y)}$$</span><br>一般情况下,  <span>$D_{n,p}$</span> 和  <span>$c_{n,p}$</span> 都是可以学习得到的. 不过在DPM中, </p>
<p><span>$D_{n,p}$</span> 是quadratic的预先定义好的.</p>
<p><strong>实例分析: </strong> 示意图中就是模拟DPM中的quadratic deformation cost, 最终的part score map通过下式计算:</p>
<p><span>$$B_p = M_p + \sum_{n=1}^4 c_{n,p} D_{n,p} + c_{5, p}\cdot \mathbf{1}$$</span><br>其中</p>
<p><span>$$\begin{eqnarray}
D_1^{(x, y)} &=& (x - r_x)^2 \\
D_2^{(x, y)} &=& (y - r_y)^2 \\
D_3^{(x, y)} &=& (x - r_x) \\
D_4^{(x, y)} &=& (y - r_y) 
\end{eqnarray}$$</span><br>这里我们省略了 part的下标. <span>$(r_x, r_y)$</span>是第p个part通过聚类得到的anchor location.</p>
<p>这一层的输出是一个 {% math p\times 1} 维的score vector.</p>
<h3 id="visibility_reasoning_and_classification">visibility reasoning and classification</h3>
<p>visibility reasoning请参照论文说明, 总之就是最后还会得到一层, 然后再做二分类 (如何准备正负样本?)</p>

      
    </div>
    <footer class="article-footer">
      
        <a data-url="http://bearpaw.github.io/blog/2015/04/05/Joint-Deep-Learning-for-Pedestrian-Detection/" data-id="6zjderp82n3stwyu" class="article-share-link" data-share="baidu">分享到</a>
      

      
        <a href="http://bearpaw.github.io/blog/2015/04/05/Joint-Deep-Learning-for-Pedestrian-Detection/#ds-thread" class="article-comment-link">Comments</a>
      

      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/Deformation-Layer/">Deformation Layer</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/Pedestrian-Detection/">Pedestrian Detection</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-latent-structural-svm" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/blog/2015/04/03/latent-structural-svm/" class="article-date">
  <time datetime="2015-04-03T05:31:12.000Z" itemprop="datePublished">4月 3 2015</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/blog/categories/论文笔记/">论文笔记</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/blog/2015/04/03/latent-structural-svm/">Latent Structural SVM</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      	  
		<!-- 文章目录开始 -->
		
		<!-- 文章目录结束 -->
        <blockquote>
<p>Yu, Chun-Nam John, and Thorsten Joachims. “Learning structural SVMs with latent variables.” ICML, 2009.</p>
</blockquote>
<h2 id="Intuition">Intuition</h2>
<p><strong>Structured Learning: </strong>传统判别式学习中, 训练样本由 <span>$\{x, y\}$</span> 构成，我们的目标是学习一个从输入到输出的映射<span>$f: x\rightarrow y$</span>. 以分类问题为例, <span>$y \in  \{1,2,3,⋯,N\}$</span> 是样本label. 但在有些问题中, 我们的输出可以是复杂的structured object, 比如parse tree, pose等等, 于是就出现了structured learning.</p>
<p><strong>Latent structured learning: </strong>在结构化学习问题中, 有一些很有用的信息可能并未在训练数据 <span>$\{x, y\}$</span>中体现出来, 如human detection问题中, 输入$x$是图像, 输出$y$是人的bounding box, 而人体各个part的位置也是很有用的信息, 但是训练数据并未包含各个part的位置, 因此需要当作latent variable. 因此很有必要在学习模型时引入这些有用的latent variable的信息.</p>
<h2 id="Model">Model</h2>
<p>在下面问题中, 训练数据集为 <span>$S = \{(x_1, y_1), \cdots, (x_n, y_n)\} \in (X\times Y)^n$</span>.</p>
<h3 id="SSVM">SSVM</h3>
<p>SSVM希望学习到下列判别函数</p>
<span>$$f_w(x) = \arg\max_{y\in Y} [w\cdot \Phi(x, y)]$$</span><br>其中 <span>$\Phi(x, y)$</span> 是表达了输入 $x$ 与输出 $y$ 之间的关系的joint feature vector. 求argmax的过程就是inference, 求解最优 $w$ 的过程就是learning.<br><br>SSVM通过在训练集上最小化risk来得到, risk定义为 <span>$\Delta (y, \hat{y})$</span>, 度量了预测结果 <span>$\hat{y}$</span> 与真实label $y$ 之间的差异. 通常情况下risk都是离散的, 非凸的, 不好优化, 因此可以找一个凸的上界, 通过最小化上界来最小化原来的risk, 这个上界可以表示为:<br><span>$$\Delta (y_i, \hat{y}_i(w)) \leq \max_{\hat{y}\in Y} [\Delta (y_i, \hat{y}) + w\cdot \Phi(x_i, \hat{y})] - w\cdot \Phi(x_i, y_i)$$</span><br>其中<br><span>$$\hat{y}_i(w) = \arg\max_{y\in Y} w\cdot \Phi(x_i, y) $$</span><br>直观理解为，max那一项是通过搜索找出最接近真实label的 <span>$\hat{y}$</span> 的得分；最后一项是真实label的真实得分 <a href="http://zhangliliang.com/2014/11/22/paper-note-latent-structural-svm/" target="_blank" rel="external">[引]</a>。<br><br>如果用SVM来formulate这个问题, 那么可以把上面定义的下届作为一个regularizer加到cost function里面, 这样就得到了下面的凸优化问题:<br><span>$$\min_w \frac{1}{2}\|w\|^2+C\sum_{i=1}^n \left[\max_{\hat{y}\in Y} [\Delta (y_i, \hat{y}) + w\cdot \Phi(x_i, \hat{y})] - w\cdot \Phi(x_i, y_i) \right]$$</span>

<h3 id="Latent_SSVM">Latent SSVM</h3>
<p>在intuition里面我们已经讨论过, 有时候输入和输出的关系不能完全由 x, y决定, 还和某个隐变量 <span>$h \in H$</span> 息息相关, joint feature 可以定义为 <span>$\Phi(x, y, h)$</span>, 这样判别函数也就变成了</p>
<span>$$f_w(x) = \arg\max_{(y, h) \in Y\times H} [w\cdot \Phi(x, y, h)]$$</span><br>类似SSVM, 我们也需要定义risk. 但是注意在现实问题中, 隐变量并不是输出 (比如DPM中, part只是中间步骤用的, 最终得到的还是整体的bbox), 因此risk不应该depend on隐变量. 这种考虑不仅更贴合实际, 而且简化了risk计算, 用数学公式可以表达如下:<br><span>$$\Delta ((y_i, h^*_i(w), (\hat{y}_i(w), \hat{h}_i(w)) = \Delta (y_i,\hat{y}_i(w), \hat{h}_i(w))$$</span><br>其中 <span>$h^*_i(w)$</span> 是”最优的”能描述x与y关系的隐变量. 基于此, risk的上界为:<br><span>$$\Delta ((y_i, h^*_i(w), (\hat{y}_i(w), \hat{h}_i(w)) \leq \left(\max_{\hat{y}, \hat{h}\in Y\times H} [\Delta (y_i, \hat{y}, \hat{h}) + w\cdot \Phi(x_i, \hat{y}, \hat{h})]\right) - \left(\max_{h\in H}w\cdot \Phi(x_i, y_i, h)\right)$$</span><br>定义好上界后, 同SSVM一样, 可以formulate成带正则项的SVM<br><span>$$\min_w \frac{1}{2}\|w\|^2+C\sum_{i=1}^n \left(\max_{\hat{y}, \hat{h}\in Y\times H} [\Delta (y_i, \hat{y}, \hat{h}) + w\cdot \Phi(x_i, \hat{y}, \hat{h})]\right) -  C\sum_{i=1}^n \left(\max_{h\in H}w\cdot \Phi(x_i, y_i, h)\right)$$</span>

<h2 id="Learning">Learning</h2>
<p>LSSVM的目标函数是两个convex function的差, 也就可以理解为convex + concave, 因此可以用Concave-Convex Procedure (<a href="http://www.stat.ucla.edu/~yuille/pubs/optimize_papers/cccp_nips01.pdf" target="_blank" rel="external">Yuille &amp; Rangarajan, 2003</a>)求解.</p>
<h3 id="CCCP">CCCP</h3>
<p>CCCP解决的是最小化两个convex function $f(w), g(w)$ 的差的算法</p>
<span>$$\min_w f(w) + (-g(w)).$$</span><br><img alt="CCCP" src="http://7u2pi6.com1.z0.glb.clouddn.com/cccp.png" width="440px"><br><br>首先, 第3行先找到一个超平面 <span>$v_t$</span>, 使得右边是 $-g(w)$ 的一个上界 , 然后最小化 $f(w) + Upperbound$ 来更新参数. CCCP能保证收敛.<br><br><h3> CCCP迭代求解LSSVM </h3><br><strong>Step 1: </strong>观察lssvm的目标函数, 我们先要找concave part的上界. 首先fix参数 <span>$w_t$</span>, 求解最优的 <span>$h^*$</span>,<br><span>$$h^* = \arg\max_{h\in H}w\cdot \Phi(x_i, y_i, h)$$</span><br>这样定义上界的超平面  <span>$v_t$</span> 为:<br><span>$$v_t = \Phi(x_i, y_i, h^*)$$</span>

<p><strong>Step 2: </strong> fix <span>$v_t$</span> , 更新模型参数 <span>$w_{t+1}$</span></p>
<p><span>$$\min_w \frac{1}{2}\|w\|^2+C\sum_{i=1}^n \max_{\hat{y}, \hat{h}\in Y\times H} [\Delta (y_i, \hat{y}, \hat{h}) + w\cdot \Phi(x_i, \hat{y}, \hat{h})] -  C\sum_{i=1}^n\max_{h\in H}w\cdot \Phi(x_i, y_i, h^*_i)$$</span><br>这一步用ssvm的求解方法解就好了.</p>

      
    </div>
    <footer class="article-footer">
      
        <a data-url="http://bearpaw.github.io/blog/2015/04/03/latent-structural-svm/" data-id="ooqka1gmcxxyhm40" class="article-share-link" data-share="baidu">分享到</a>
      

      
        <a href="http://bearpaw.github.io/blog/2015/04/03/latent-structural-svm/#ds-thread" class="article-comment-link">Comments</a>
      

      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/latent-ssvm/">latent ssvm</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/ssvm/">ssvm</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Generalized-Distance-Transform" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/blog/2015/04/01/Generalized-Distance-Transform/" class="article-date">
  <time datetime="2015-04-01T12:46:50.000Z" itemprop="datePublished">4月 1 2015</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/blog/categories/知识库/">知识库</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/blog/2015/04/01/Generalized-Distance-Transform/">Generalized Distance Transform</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      	  
		<!-- 文章目录开始 -->
		
		<!-- 文章目录结束 -->
        <p>距离变换于1966年被学者首次提出,目前已被广泛应用于图像分析、计算机视觉、模式识别等领域，人们利用它来实现目标细化、骨架提取、形状插值及匹配、粘连物体的分离等。距离变换是针对二值图像的一种变换。在二维空间中，一幅二值图像可以认为仅仅包含目标和背景两种像素，目标的像素值为1，背景的像素值为0；距离变换的结果不是另一幅二值图像，而是一幅灰度级图像，即距离图像，图像中每个像素的灰度值为该像素与距其最近的背景像素间的距离, 如下图所示。<a href="http://blog.csdn.net/carson2005/article/details/21617897" target="_blank" rel="external">[参考: 距离变换]</a></p>
<p><img src="http://7u2pi6.com1.z0.glb.clouddn.com/@/blog/dt.png" alt="Distance Transform"></p>
<h2 id="传统距离变换">传统距离变换</h2>
<p>传统DT定义在grid的点上. 给定grid $G$, 令 $x, y$ 是 $G$ 上的两个点, 并且定义距离度量 $d(x, y)$. 给定一个集合 <span>$B \subseteq G$</span>, 那么 $B$ 在 $G$ 上的距离变换 <span>$D_B(x)$</span> 就定义为<strong>$G$ 上的每个点到 $B$ 的最近距离</strong>:</p>
<span>$$D_B(x) = \min_{y\in B} d(x, y).$$</span>

<p>如果我们在 $G$ 上定义一个 indicator function <span>$\mathbf{1}_B(y)$</span>:</p>
<span>$$\mathbf{1}_B(y) :=
	\begin{cases} 
	0 &\text{if } y \in B, \\
	\infty &\text{if } y \notin B.
	\end{cases}$$</span><br>那么DT可以重新formulate为下列形式:<br><span>$$D_B(x) = \min_{y\in G} (d(x, y) + \mathbf{1}_B(y)).$$</span><br>这和本文开篇的例子是一致的.<br><br><h3> Generalized 距离变换 </h3><br>上一节定义的 <span>$\mathbf{1}_B(y)$</span> 是一个定义在 $G$ 上的二值函数, 假设我们将其替换成定义在 $G$ 上的任意函数 $f(y)$, 就得到了generalized DT:<br><span>$$D_f(x) = \min_{y\in G} (d(x, y) + f(y)).$$</span>

<p>假设 $G$ 上共有 $k$ 个点, 那么对每一个 $G$ 上的点, 都需要将所有点扫描一次, 因此算法复杂度是 $O(k^2)$. 从上面式子可以看出, DT 直观上是对 $x$ 找到对应的 $y$, 使得 $x, y$ 之间的距离尽可能小, 同时函数值 $f(y)$ 也要小.</p>
<h3 id="参考">参考</h3>
<ol>
<li><a href="http://blog.csdn.net/abcjennifer/article/details/7617883" target="_blank" rel="external">距离变换 (Rachel Zhang的专栏)</a></li>
<li>Pictorial Structures for Object Recognition. Felzenszwalb, Pedro F., and Daniel P. Huttenlocher. IJCV (2005).</li>
<li>An example on using the distance transform can be found at <code>opencv_source_code/samples/cpp/distrans.cpp</code></li>
</ol>

      
    </div>
    <footer class="article-footer">
      
        <a data-url="http://bearpaw.github.io/blog/2015/04/01/Generalized-Distance-Transform/" data-id="7qtq2m0395d80z9s" class="article-share-link" data-share="baidu">分享到</a>
      

      
        <a href="http://bearpaw.github.io/blog/2015/04/01/Generalized-Distance-Transform/#ds-thread" class="article-comment-link">Comments</a>
      

      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/distance-transform/">distance transform</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Git-in-a-Nutshell" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/blog/2015/03/25/Git-in-a-Nutshell/" class="article-date">
  <time datetime="2015-03-25T01:51:05.000Z" itemprop="datePublished">3月 25 2015</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/blog/categories/工具/">工具</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/blog/2015/03/25/Git-in-a-Nutshell/">Git in a Nutshell</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>本文主要介绍git常用操作, 包括同步fork, 解决merge 冲突等等.</p>
<p>
        
          <p class="article-more-link">
            <a href="/blog/2015/03/25/Git-in-a-Nutshell/#more">Read More</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      
        <a data-url="http://bearpaw.github.io/blog/2015/03/25/Git-in-a-Nutshell/" data-id="lnfp9414ls6pckh3" class="article-share-link" data-share="baidu">分享到</a>
      

      
        <a href="http://bearpaw.github.io/blog/2015/03/25/Git-in-a-Nutshell/#ds-thread" class="article-comment-link">Comments</a>
      

      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/git/">git</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Articulated-Pose-Estimation-by-a-Graphical-Model-with-Image-Dependent-Pairwise-Relations" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/blog/2015/03/19/Articulated-Pose-Estimation-by-a-Graphical-Model-with-Image-Dependent-Pairwise-Relations/" class="article-date">
  <time datetime="2015-03-19T02:02:28.000Z" itemprop="datePublished">3月 19 2015</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/blog/categories/论文笔记/">论文笔记</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/blog/2015/03/19/Articulated-Pose-Estimation-by-a-Graphical-Model-with-Image-Dependent-Pairwise-Relations/">Articulated Pose Estimation by a Graphical Model with Image Dependent Pairwise Relations</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <blockquote>
<p>Chen, Xianjie, and Alan L. Yuille. “Articulated pose estimation by a graphical model with image dependent pairwise relations.” Advances in Neural Information Processing Systems. 2014.</p>
</blockquote>
<p>本文在YANG Yi工作的基础上, 利用CNN学习part detector以及pairwise part relations, 并利用图模型进行Inference, 从而估计出最终的pose.<br><img src="http://www.stat.ucla.edu/~xianjie.chen/image/nips14_pose.png" alt="图1. Motivation: 通过观察可以发现, local patch可以告诉我们两个信息. 1) 我们可以通过合适的local patch判断它是哪一个body part; 2) 在知道local patch是哪一个part后, 我们还可以看出其相邻的part可能出现的位置. 如中间的示例所示, 通过以elbow为中心的patch, 我们能够推理出shoulder和wrist的相对位置 (如左图); 通过以wrist为中心的patch, 我们能够推理出elbow的相对位置 (如右图). "></p>
<p>
        
          <p class="article-more-link">
            <a href="/blog/2015/03/19/Articulated-Pose-Estimation-by-a-Graphical-Model-with-Image-Dependent-Pairwise-Relations/#more">Read More</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      
        <a data-url="http://bearpaw.github.io/blog/2015/03/19/Articulated-Pose-Estimation-by-a-Graphical-Model-with-Image-Dependent-Pairwise-Relations/" data-id="ilyli4970yo24vrk" class="article-share-link" data-share="baidu">分享到</a>
      

      
        <a href="http://bearpaw.github.io/blog/2015/03/19/Articulated-Pose-Estimation-by-a-Graphical-Model-with-Image-Dependent-Pairwise-Relations/#ds-thread" class="article-comment-link">Comments</a>
      

      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/Deep-Learning/">Deep Learning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/pose-estimation/">pose estimation</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Logistic-Regression" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/blog/2015/02/09/Logistic-Regression/" class="article-date">
  <time datetime="2015-02-09T01:26:01.000Z" itemprop="datePublished">2月 9 2015</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/blog/categories/知识库/">知识库</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/blog/2015/02/09/Logistic-Regression/">Logistic Regression</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Logistic Regression (以下简称LR)解决的是分类问题. 考虑两类分类问题, 如判断邮件是否是垃圾邮件, 或肿瘤是否为恶性肿瘤, 样本标签只有两类: 0表示negtive, 1表示positive. 考虑用之前讨论过的Linear regression来解决这个问题, 如图1所示, 当样本分布理想时, 可以通过设定阈值来对样本进行分类 (绿色); 但是当样本分布不理想时, 拟合出来的linear function偏差比较大, 设定阈值的方法不能获得理想的分类结果 (蓝色). Linear regression的另一个问题是其给出的预测范围是 $h(x) \in (-\infty, \infty)$, 而分类问题的标签就两个$\{0, 1\}$, 其理想的predict function应该是 $h(x) \in [0, 1]$, 所以linear regression也不适合分类问题.</p>
<p><img src="http://7u2pi6.com1.z0.glb.clouddn.com/blog/linear-regression-for-classification.png" alt="图1. 用linear regression模型解决分类问题"></p>
<p>
        
          <p class="article-more-link">
            <a href="/blog/2015/02/09/Logistic-Regression/#more">Read More</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      
        <a data-url="http://bearpaw.github.io/blog/2015/02/09/Logistic-Regression/" data-id="q4g0o8x22xegxlpm" class="article-share-link" data-share="baidu">分享到</a>
      

      
        <a href="http://bearpaw.github.io/blog/2015/02/09/Logistic-Regression/#ds-thread" class="article-comment-link">Comments</a>
      

      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/Logistic-regression/">Logistic regression</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/classification/">classification</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/gradient-descent/">gradient descent</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/newton-method/">newton method</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/optimization/">optimization</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Linear-Regression" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/blog/2015/02/06/Linear-Regression/" class="article-date">
  <time datetime="2015-02-06T05:48:00.000Z" itemprop="datePublished">2月 6 2015</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/blog/categories/知识库/">知识库</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/blog/2015/02/06/Linear-Regression/">Linear Regression</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><img src="http://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Linear_regression.svg/438px-Linear_regression.svg.png" alt="图1. Linear regression"></p>
<h2 id="引子">引子</h2>
<p>如图1所示, 我们以一个不够恰当的例子来引入线性回归的问题: 假设横轴表示焦虑程度, 纵轴表示抽烟的根数, 蓝点表示历史数据. 我们想要了解这样的问题: 假设今天我的焦虑程度为31, 能否根据历史数据预测我今天的抽烟根数?</p>

        
          <p class="article-more-link">
            <a href="/blog/2015/02/06/Linear-Regression/#more">Read More</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      
        <a data-url="http://bearpaw.github.io/blog/2015/02/06/Linear-Regression/" data-id="ka21xn63v8lowpkj" class="article-share-link" data-share="baidu">分享到</a>
      

      
        <a href="http://bearpaw.github.io/blog/2015/02/06/Linear-Regression/#ds-thread" class="article-comment-link">Comments</a>
      

      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/gradient-descent/">gradient descent</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/linear-regression/">linear regression</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-hinge-loss" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/blog/2015/02/05/hinge-loss/" class="article-date">
  <time datetime="2015-02-05T07:32:14.000Z" itemprop="datePublished">2月 5 2015</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/blog/categories/知识库/">知识库</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/blog/2015/02/05/hinge-loss/">Hinge Loss</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      	  
		<!-- 文章目录开始 -->
		
		<!-- 文章目录结束 -->
        <h2 id="概述">概述</h2>
<p>Hinge loss是广泛应用于分类问题中的loss function。假设样本的真实标签为$t=\pm 1$,  分类器对样本的打分为$y$. 注意这里$y$是实数, 而不是样本标签$\pm 1$. Hinge loss定义如下:</p>
<span>$$L_{hinge}(y) = \max(0, 1-t\cdot y). $$</span>

<p>假设$t$与$y$的符号相同, 即$y$是正确的预测, 且$|y| \geq 1$, 则此时hinge loss为0. 否则, $1-t\cdoty \geq 0$, hinge loss不为0, 且随着$y$减小而线性增大.</p>
<h2 id="性质">性质</h2>
<p>Hinge Loss是凸函数. 虽然不可导, 但是可以求解其次梯度(subgradient). 假设$y=w\cdot x$, 那么hinge loss关于参数$w$的subgradient为</p>
<p><span>$$\frac{\partial L_{hinge}}{\partial w_i} = \begin{cases} -t \cdot x_i & \text{if } t \cdot y < 1 \\ 0 & \text{otherwise} \end{cases}$$</span></p>
<h2 id="参考文献">参考文献</h2>
<ol>
<li><a href="http://en.wikipedia.org/wiki/Hinge_loss" target="_blank" rel="external">Wikipedia</a></li>
</ol>

      
    </div>
    <footer class="article-footer">
      
        <a data-url="http://bearpaw.github.io/blog/2015/02/05/hinge-loss/" data-id="tnx8rnds5s2lenvb" class="article-share-link" data-share="baidu">分享到</a>
      

      
        <a href="http://bearpaw.github.io/blog/2015/02/05/hinge-loss/#ds-thread" class="article-comment-link">Comments</a>
      

      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/hinge-loss/">hinge loss</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Network" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/blog/2015/01/29/Network/" class="article-date">
  <time datetime="2015-01-29T07:52:37.000Z" itemprop="datePublished">1月 29 2015</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/blog/categories/工具/">工具</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/blog/2015/01/29/Network/">Caffe 将全连接网络转化为全卷积网络</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>当我们用Caffe训练好一个网络，希望用其进行测试时，我们会写一个deploy.prototxt, 以CaffeNet为例，该文件的前几行是这样的：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="attribute">name</span>: <span class="string">"CaffeNet"</span></div><div class="line"><span class="attribute">input</span>: <span class="string">"data"</span></div><div class="line"><span class="attribute">input_dim</span>: <span class="string">10</span></div><div class="line"><span class="attribute">input_dim</span>: <span class="string">3</span></div><div class="line"><span class="attribute">input_dim</span>: <span class="string">227</span></div><div class="line"><span class="attribute">input_dim</span>: <span class="string">227</span></div></pre></td></tr></table></figure>

<p>其中前两行分别是网络的名称，输入层blob的名字， 以及数据维度(n, c, h, w). 这样我们就能对大小与训练数据大小一致的图像进行分类。然而有时候我们希望对不同大小的图像进行测试，如果以这些图像进行输入，那么在卷积层结束进入全连接（Fully Connected, FC）层时，程序会发现FC层的输入和训练时的输入不一致，导致程序崩溃。一个处理方法是将输入图像resize到标准大小，然后这样可能会导致图像失真，因此有时我们需要将网络转化为全卷积网络。</p>
<p>
        
          <p class="article-more-link">
            <a href="/blog/2015/01/29/Network/#more">Read More</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      
        <a data-url="http://bearpaw.github.io/blog/2015/01/29/Network/" data-id="u996braoevaba5pt" class="article-share-link" data-share="baidu">分享到</a>
      

      
        <a href="http://bearpaw.github.io/blog/2015/01/29/Network/#ds-thread" class="article-comment-link">Comments</a>
      

      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/Caffe/">Caffe</a></li></ul>

    </footer>
  </div>
  
</article>


  
  
    <nav id="page-nav">
      <span class="page-number current">1</span><a class="page-number" href="/blog/archives/2015/page/2/">2</a><a class="extend next" rel="next" href="/blog/archives/2015/page/2/">Next &raquo;</a>
    </nav>
  
</section>
      
      <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">分类</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/blog/categories/工具/">工具</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/blog/categories/机器学习/">机器学习</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/blog/categories/知识库/">知识库</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/blog/categories/论文笔记/">论文笔记</a><span class="category-list-count">5</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/blog/tags/Caffe/">Caffe</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/blog/tags/DPM/">DPM</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/blog/tags/Deep-Learning/">Deep Learning</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/blog/tags/Deformation-Layer/">Deformation Layer</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/blog/tags/HOG/">HOG</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/blog/tags/Logistic-regression/">Logistic regression</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/blog/tags/MCMC/">MCMC</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/blog/tags/Pedestrian-Detection/">Pedestrian Detection</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/blog/tags/articulated-pose-estimation/">articulated pose estimation</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/blog/tags/classification/">classification</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/blog/tags/distance-transform/">distance transform</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/blog/tags/feature/">feature</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/blog/tags/git/">git</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/blog/tags/gradient-descent/">gradient descent</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/blog/tags/hinge-loss/">hinge loss</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/blog/tags/human-detection/">human detection</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/blog/tags/latent-ssvm/">latent ssvm</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/blog/tags/linear-regression/">linear regression</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/blog/tags/mixtures-of-parts/">mixtures of parts</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/blog/tags/newton-method/">newton method</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/blog/tags/optimization/">optimization</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/blog/tags/pictorial-model/">pictorial model</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/blog/tags/pose-estimation/">pose estimation</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/blog/tags/sampling/">sampling</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/blog/tags/ssvm/">ssvm</a><span class="tag-list-count">1</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签云</h3>
    <div class="widget tagcloud">
      <a href="/blog/tags/Caffe/" style="font-size: 10.00px;">Caffe</a><a href="/blog/tags/DPM/" style="font-size: 10.00px;">DPM</a><a href="/blog/tags/Deep-Learning/" style="font-size: 10.00px;">Deep Learning</a><a href="/blog/tags/Deformation-Layer/" style="font-size: 10.00px;">Deformation Layer</a><a href="/blog/tags/HOG/" style="font-size: 20.00px;">HOG</a><a href="/blog/tags/Logistic-regression/" style="font-size: 10.00px;">Logistic regression</a><a href="/blog/tags/MCMC/" style="font-size: 10.00px;">MCMC</a><a href="/blog/tags/Pedestrian-Detection/" style="font-size: 10.00px;">Pedestrian Detection</a><a href="/blog/tags/articulated-pose-estimation/" style="font-size: 10.00px;">articulated pose estimation</a><a href="/blog/tags/classification/" style="font-size: 10.00px;">classification</a><a href="/blog/tags/distance-transform/" style="font-size: 10.00px;">distance transform</a><a href="/blog/tags/feature/" style="font-size: 10.00px;">feature</a><a href="/blog/tags/git/" style="font-size: 10.00px;">git</a><a href="/blog/tags/gradient-descent/" style="font-size: 20.00px;">gradient descent</a><a href="/blog/tags/hinge-loss/" style="font-size: 10.00px;">hinge loss</a><a href="/blog/tags/human-detection/" style="font-size: 10.00px;">human detection</a><a href="/blog/tags/latent-ssvm/" style="font-size: 10.00px;">latent ssvm</a><a href="/blog/tags/linear-regression/" style="font-size: 10.00px;">linear regression</a><a href="/blog/tags/mixtures-of-parts/" style="font-size: 10.00px;">mixtures of parts</a><a href="/blog/tags/newton-method/" style="font-size: 10.00px;">newton method</a><a href="/blog/tags/optimization/" style="font-size: 10.00px;">optimization</a><a href="/blog/tags/pictorial-model/" style="font-size: 10.00px;">pictorial model</a><a href="/blog/tags/pose-estimation/" style="font-size: 10.00px;">pose estimation</a><a href="/blog/tags/sampling/" style="font-size: 10.00px;">sampling</a><a href="/blog/tags/ssvm/" style="font-size: 10.00px;">ssvm</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/blog/archives/2015/04/">April 2015</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/blog/archives/2015/03/">March 2015</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/blog/archives/2015/02/">February 2015</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/blog/archives/2015/01/">January 2015</a><span class="archive-list-count">4</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">近期文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/blog/2015/04/16/Parsing-Occluded-People-by-Flexible-Compositions/">(no title)</a>
          </li>
        
          <li>
            <a href="/blog/2015/04/05/Joint-Deep-Learning-for-Pedestrian-Detection/">Joint Deep Learning for Pedestrian Detection</a>
          </li>
        
          <li>
            <a href="/blog/2015/04/03/latent-structural-svm/">Latent Structural SVM</a>
          </li>
        
          <li>
            <a href="/blog/2015/04/01/Generalized-Distance-Transform/">Generalized Distance Transform</a>
          </li>
        
          <li>
            <a href="/blog/2015/03/25/Git-in-a-Nutshell/">Git in a Nutshell</a>
          </li>
        
      </ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">友情链接</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="http://mmlab.ie.cuhk.edu.hk/" target="_blank">CUHK MMLAB</a>
          </li>
        
          <li>
            <a href="http://vision.sysu.edu.cn/" target="_blank">SYSU IMC LAB</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2015 Plateo<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/xiangming/landscape-plus" target="_blank">Landscape-plus</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/blog/" class="mobile-nav-link">Blog</a>
  
    <a href="/blog/PRML" class="mobile-nav-link">PRML</a>
  
    <a href="/blog/Deep-Learning" class="mobile-nav-link">Deep Learning</a>
  
    <a href="/blog/archives" class="mobile-nav-link">Archives</a>
  
    <a href="http://bearpaw.github.io" class="mobile-nav-link">About</a>
  
</nav>
  <!-- totop start -->
<div id="totop">
<a title="返回顶部"><img src="/blog/img/scrollup.png"/></a>
</div>

<!-- totop end -->

<!-- 多说公共js代码 start -->
<script type="text/javascript">
var duoshuoQuery = {short_name:"platero"};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
     || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
  </script>
<!-- 多说公共js代码 end -->


<!-- 百度分享 start -->

<div id="article-share-box" class="article-share-box">
  <div id="bdshare" class="bdsharebuttonbox article-share-links">
    <a class="article-share-weibo" data-cmd="tsina" title="分享到新浪微博"></a>
    <a class="article-share-weixin" data-cmd="weixin" title="分享到微信"></a>
    <a class="article-share-qq" data-cmd="sqq" title="分享到QQ"></a>
    <a class="article-share-renren" data-cmd="renren" title="分享到人人网"></a>
    <a class="article-share-more" data-cmd="more" title="更多"></a>
  </div>
</div>
<script>window._bd_share_config={"common":{},"share":{"bdCustomStyle":"nocss.css"}};with(document)0[(getElementsByTagName("head")[0]||body).appendChild(createElement("script")).src="http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion="+~(-new Date()/36e5)];</script>

<!-- 百度分享 end -->

<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>




<! -- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],displayMath: [['\\[','\\]'], ['$$','$$']],
                processEscapes: true
                    
}
  
        });
</script>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
                  
}
    
        });
</script>

<script type="text/x-mathjax-config">
MathJax.Hub.Queue(function() {
            var all = MathJax.Hub.getAllJax(), i;
            for(i=0; i < all.length; i += 1) {
                            all[i].SourceElement().parentNode.className += ' has-jax';
                                    
            }
                
        });
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<script src="/blog/js/script.js" type="text/javascript"></script>


</div>
<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
</body>
</html>
